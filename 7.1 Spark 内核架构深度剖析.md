## 7.1 Spark 内核架构深度剖析

```
1. Application
2. spark-submit
3. Driver
4. SparkContext
5. Master
6. Worker
7. Executor
8. Job
9. DAGScheduler 
10. TaskScheduler 
11. ShuffleMapTask and ResultTask
```

1. 将自己编写的程序（Application）打成 jar 包上传到 spark 机器，通过 Xshell 的 spark-submit 来提交该 。
2. 提交 Spark 应用后，会在机器上启动 Driver，之前的提交方式 Standalone 通过反射的方式创建和构造一个 DriverActor进程。
3. Driver 进程会执行 Application 程序，在执行 Application 时，首先会 构造 SparkContext 对象。
4. SparkContext 在初始化的时候最重要的事情是构造出 DAGScheduler 和 TaskScheduler。
5. 在构造 TaskScheduler 时会向 Master 发出请求，向 Master 注册 Application。Master 接收到 Application 注册的请求后，会使用资金的资源调度算法，在 Spark 集群的 Worker 上为这个 Application 启动多个 Executor。
7. 启动 Executor 后，会自己反向注册到 TaskScheduler 上。
8. 所有 Executor 都反向注册到 Driver 后，Driver 会结束 SparkContext 的初始化，然后继续执行我们自己的 Application 的代码。每执行到一个 action，就会创建一个 job。
9. job 会提交给 DAGScheduler，DAGScheduler 会将 job 划分为多个 stage，然后每个 stage 会创建一个 taskset（stage 划分算法）。
10. 每个 taskset 会给到 TaskScheduler，TaskScheduler 会把 taskset 里每一个 task 提交到 Executor 上执行（task 分配算法）。
11. Executor 每接受到一个 task，都会 TaskRunner 封装 task，然后从线程池中取出线程执行这个 task。
12. TaskRunner 将要执行的算子和函数，拷贝，反序列化，然后执行 task。
13. Task（ShuffleMapTask，ResultTask），只有最后一个 stage 是 ResultTask，其余之前的是 stage 都是 ShuffleMapTask。
14. **所以最后整个 Spark 应用程序的执行，都是 Stage 分批次将 taskset 提交到 executor 执行，每个 task 针对 RDD 的一个 partition 执行定义的算子和函数。依次类推，直到所有操作执行完成。**