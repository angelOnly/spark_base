## Spark 架构原理
### Driver
我们编写的 Spark 程序就在 Driver 上，Spark 集群的节点之一就是提交 Saprk 程序的机器
### Master 和 Worker
Master 和 Worker 在 spark 的 slaves 文件中进行配置，在我本地的机器中，Spark1 是 Master 节点，Spark2 和 Saprk3 是 Worker 节点。可通过 jps 查看。
1. Master 和 Worker 是进程
2. Master 主要负责资源调度和分配，还有集群的监控
3. worker 主要负责两个，一是用自己的内存存储 RDD 某个或某些 partition，二是启动其他进程和线程，对 RDD 上的 partition 进行处理和计算。
### Executor 和 Task
在 Worker 节点中，Executor 和 Task 负责对 RDD 进行并行计算，也就是执行我们对 RDD 的定义，如：map，flatmap，reduce 等操作。
### 流程
1. Driver 进程启动之后，会做一些初始化操作，在这个过程中会发送一些请求到 Master 上，进行 Spark 应用程序的注册。
2. Master 接收到 Spark 应用程序的注册申请之后，会发送请求给 Worker 进行资源调度和分配。
3. Worker 接收到 Master 的请求之后，会为 spark 应用启动 Executor ，Executor 启动后，会向 Driver 进行反注册，这样 Driver 就知道哪些 Executor 是为他注册的。
4. Driver 注册了一些 Executor 后就可以开始正式执行 Spark 应用程序。
5. HDFS 文件被读到多个 Worker 节点上，形成内存中的分布式数据集，也就是初始 RDD。此时 Worker 中就会存在一些 RDD partition。
6. Driver 会根据我们对 RDD 定义的操作，提交一堆 Task 到 Executor 上。Executor 接收到 Task 之后会启动多个 Task 执行。
7. Task 会对 RDD 的partition 数据进行指定的算子操作形成新的 RDD partition。