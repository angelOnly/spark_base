## 5.1 共享变量工作原理
Spark 的一个非常重要的特性就是 **共享变量**。

默认情况下，如果一个算子的函数中使用到了某个外部变量，那么这个变量的值会被拷贝到每个 task 中。此时每个 task 只能操作自己的那份变量副本。如果多个 task 想要共享某个变量，那么这种方式是做不到的。

Spark 为此提供了两种变量：
- BroadCast Variable（广播变量）

    -  BroadCast Variable 是只读的， 并且在每个节点只会有一份副本，而不是为每个 task 拷贝一份副本，其最大的作用就是减少变量到各个节点的网络传输消耗，以及在各个节点上的内存消耗。
    - 此外，Spark 内部也使用了高校的广播算法来减少网络消耗。
    - 可通过调用 SparkContext 的 broadcast() 方法，来针对某个变量创建广播变量。然后在算子的函数内，使用到广播变量时，每个节点只会拷贝一份副本。每个节点可以使用广播变量的 value() 方法获取值。
    
    ```
    val factor = 3
    val factorBroadcast = sc.broadcast(factor)
    
    val arr = Array(1,2,3,4,5)
    val rdd = sc.parallelize(arr)
    val multiRdd = rdd.map(num => num*factorBroadcast.value())
    
    multiRdd.foreach(num => println(num))
    ```
- Accumulator（累加变量）

    - Accumulator 主要用于多个节点对同一个变量进行共享性操作。
    - Accumulator 只提供了累加的操作，即多个 task 对一个变量的并行操作功能。
    - 但是 task 只能对 Accumulator 进行累加，不能读取它的值，只有 Driver 程序可以读取它的值。
    
    ```
    val sum = sc.accumulator(0)
    val arr = Array(1,2,3,4,5)
    val rdd = sc.parallelize(arr)
    
    rdd.foreach(num => sum += num)
    
    println(sum.value)
    ```
