## Spark 实现 scala 版 WordCount
````scala
package cn.spark.study.core

import com.sun.tools.javac.code.Attribute.Array
import org.apache.spark.SparkConf
import org.apache.spark.SparkContext

/**
 * @author Administrator
 */
object WordCount {
  
  def main(args: Array[String]) {
    val conf = new SparkConf()
        .setAppName("WordCount");
    val sc = new SparkContext(conf)
  
    val lines = sc.textFile("hdfs://spark1:9000/spark.txt", 1); 
    val words = lines.flatMap { line => line.split(" ") }   
    val pairs = words.map { word => (word, 1) }   
    val wordCounts = pairs.reduceByKey { _ + _ }
    
    wordCounts.foreach(wordCount => println(wordCount._1 + " appeared " + wordCount._2 + " times."))  
  }
  
}
````

### yarn client 提交方式

````shell
 ~/spark-submit --master yarn --deploy-mode cluster --class cn.spark.study.core.WordCount spark-study-scala.jar 100
````

[Spark中yarn模式两种提交任务方式](https://blog.csdn.net/LHWorldBlog/article/details/79300036)

